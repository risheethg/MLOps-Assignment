# âš¡ For Q3, CPU Usage Prediction with DVC + MLflow

This project demonstrates an **end-to-end MLOps pipeline** for predicting CPU usage using machine learning models.  
It uses **DVC** for reproducible pipelines and data versioning, and **MLflow** for experiment tracking & model management.

---

## ğŸ”§ 1. Environment Setup

Install dependencies:
```bash
pip install dvc[all] mlflow scikit-learn xgboost optuna matplotlib seaborn shap
# Optional: For neural networks
pip install torch
```

Initialize Git & DVC in your project folder:
```bash
git init
dvc init
```

## ğŸ“‚ 2. Project Structure

A clean layout inside VS Code:
```bash
cpu-usage-prediction/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw.csv
â”‚   â””â”€â”€ processed.csv          # generated by preprocess.py
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocess.py           # cleans raw.csv â†’ processed.csv
â”‚   â”œâ”€â”€ train.py                # trains model, logs metrics to MLflow
â”‚   â””â”€â”€ evaluate.py             # optional: extra evaluation & explainability
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ model.pkl               # trained model artifacts
â”‚
â”œâ”€â”€ dvc.yaml                    # pipeline definition
â”œâ”€â”€ dvc.lock                    # pipeline lock file (auto-generated)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ“Š 3. Data Versioning (DVC)

Track your dataset:
```bash
dvc add data/raw.csv
git add data/raw.csv.dvc .gitignore
git commit -m "Add raw dataset"
```

If you have remote storage (Google Drive, S3, etc.):
```bash
dvc remote add -d storage <remote-url>
dvc push
```

## âš™ï¸ 4. DVC Pipeline

`dvc.yaml` defines the pipeline stages:
```yaml
stages:
  preprocess:
    cmd: python src/preprocess.py data/raw.csv data/processed.csv
    deps:
      - src/preprocess.py
      - data/raw.csv
    outs:
      - data/processed.csv

  train:
    cmd: python src/train.py data/processed.csv models/
    deps:
      - src/train.py
      - data/processed.csv
    outs:
      - models/model.pkl
```

Run the full pipeline:
```bash
dvc repro
```

## ğŸ“ˆ 5. Experiment Tracking (MLflow)

Start MLflow UI:
```bash
mlflow ui --host 127.0.0.1 --port 5000 --workers 1
```

Open your browser at:
```
http://127.0.0.1:5000
```

You will see:
- Parameters (model type, hyperparameters)
- Metrics (RMSE, MAE, RÂ²)
- Artifacts (trained models, plots, SHAP explanations)
- Model versions

## ğŸš€ 6. Example Workflow

1. Add/update dataset (`data/raw.csv`).
2. Run pipeline with DVC:
   ```bash
   dvc repro
   ```
3. Track results in MLflow UI.
4. Push dataset & artifacts to remote:
   ```bash
   dvc push
   ```

## âœ… 7. Supported Models

- Linear Regression
- Random Forest
- XGBoost
- (Optional) MLP (PyTorch)

Easily extendable with Optuna hyperparameter tuning

## ğŸ“ Notes

- `src/train.py` logs metrics & models to MLflow automatically.
- Change model type by modifying the command in `dvc.yaml`.
- Use Optuna inside `train.py` for auto-hyperparameter tuning.

## ğŸ› ï¸ Implementation Files

### requirements.txt
```
dvc[all]
mlflow
scikit-learn
xgboost
optuna
matplotlib
seaborn
shap
pandas
numpy
torch
```

### dvc.yaml
```yaml
stages:
  preprocess:
    cmd: python src/preprocess.py data/raw.csv data/processed.csv
    deps:
      - src/preprocess.py
      - data/raw.csv
    outs:
      - data/processed.csv

  train:
    cmd: python src/train.py data/processed.csv models/ --model_type xgboost
    deps:
      - src/train.py
      - data/processed.csv
    outs:
      - models/model.pkl
    params:
      - model_type
      - hyperparameters

  evaluate:
    cmd: python src/evaluate.py models/model.pkl data/processed.csv
    deps:
      - src/evaluate.py
      - models/model.pkl
      - data/processed.csv
```

### params.yaml
```yaml
model_type: "xgboost"  # options: linear, random_forest, xgboost, mlp
hyperparameters:
  xgboost:
    n_estimators: 100
    max_depth: 6
    learning_rate: 0.1
  random_forest:
    n_estimators: 100
    max_depth: 10
  linear:
    alpha: 1.0
```

## ğŸ”„ Pipeline Execution

1. **Data Preprocessing**: Cleans and prepares raw CPU usage data
2. **Model Training**: Trains selected model with hyperparameter tuning
3. **Model Evaluation**: Generates performance metrics and SHAP explanations
4. **Experiment Tracking**: Logs everything to MLflow for comparison

## ğŸ“Š MLflow Integration

The pipeline automatically tracks:
- **Parameters**: Model type, hyperparameters, data preprocessing steps
- **Metrics**: RMSE, MAE, RÂ², training time
- **Artifacts**: Trained models, feature importance plots, SHAP visualizations
- **Models**: Versioned models ready for deployment

## ğŸ¯ Getting Started

1. Clone this repository
2. Install dependencies: `pip install -r requirements.txt`
3. Initialize DVC: `dvc init`
4. Add your CPU usage data to `data/raw.csv`
5. Run the pipeline: `dvc repro`
6. View results: `mlflow ui`

## ğŸ” Model Comparison

Use MLflow UI to compare different models and hyperparameters across experiments. The pipeline supports easy switching between model types and automatic hyperparameter optimization with Optuna.
